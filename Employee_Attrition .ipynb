{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df <- read.csv(\"../input/ibm-attrition-analysis/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nhead(df)\n\n# This will be used for training and testing.\noriginal_df <- df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"library(dplyr)\ndf %>% glimpse()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"library(ggcorrplot)\noptions(repr.plot.width=10, repr.plot.height=7) \n\nnums <- select_if(df, is.numeric)\n\ncorr <- round(cor(nums), 1)\n\nggcorrplot(corr, \n           type = \"lower\", \n           lab = TRUE, \n           lab_size = 3, \n           method=\"square\", \n           colors = c(\"tomato2\", \"white\", \"#01A9DB\"), \n           title=\"Correlogram Employee Attritions\", \n           ggtheme=theme_minimal())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set.seed(142)\nlibrary(caret)\n# # I personally prefer to shuffle my data before splitting.\noriginal_df <- original_df[sample(nrow(original_df)),]\n\n# Let's encode the ordinal variables\noriginal_df$BusinessTravel = factor(original_df$BusinessTravel,\n                         levels = c('Travel_Frequently', 'Travel_Rarely', 'Non-Travel'),\n                         labels = c(1, 2, 3))\n\n\n\n# Changing the datatype from integer to factors from the ordinal variables.\ncols <- c(\"Education\", \"EnvironmentSatisfaction\", \"JobInvolvement\", \"JobLevel\",\n         \"JobSatisfaction\", \"PerformanceRating\", \"RelationshipSatisfaction\", \n         \"StockOptionLevel\", \"TrainingTimesLastYear\", \"WorkLifeBalance\")\n\noriginal_df[cols] <- lapply(original_df[cols], factor)\n\n# Delete unecessary columns\ncols <- c(\"Over18\", \"EmployeeNumber\", \"EmployeeCount\")\n\noriginal_df[cols] <- NULL\n\n\n# Splitting our data\ntrainIndex <- createDataPartition(original_df$Attrition, p=0.8, \n                                 list=FALSE, times=1)\n\ntrain <- original_df[trainIndex,]\ntest <- original_df[-trainIndex,]\n\n\n\n# Checking that both the training and testing sets have the same label proportions.\nprop_train <- train %>% select(Attrition) %>% group_by(Attrition) %>% summarize(n=n()) %>%\nmutate(pct=round(prop.table(n), 2))\n\nprop_test <- test %>% select(Attrition) %>% group_by(Attrition) %>% summarize(n=n()) %>%\nmutate(pct=round(prop.table(n), 2))\n\nprop_train\nprop_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"library(rpart)\noptions(repr.plot.width=10, repr.plot.height=8) \n\nrpart.tree <- rpart(Attrition ~ ., data=train)\nplot(rpart.tree, uniform=TRUE, branch=0.6, margin=0.05)\ntext(rpart.tree, all=TRUE, use.n=TRUE)\ntitle(\"Training Set's Classification Tree\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"options(repr.plot.width=8, repr.plot.height=6) \nlibrary(ggplot2)\nlibrary(ggthemes)\npredictions <- predict(rpart.tree, test, type=\"class\")\nconf_df <- data.frame(table(test$Attrition, predictions))\nsummary(predictions)\nconfusionMatrix(table(test$Attrition, predictions))\n\nggplot(data =  conf_df, mapping = aes(x = predictions, y = Var1)) +\n  geom_tile(aes(fill = Freq), colour = \"white\") +\n  geom_text(aes(label = sprintf(\"%1.0f\", Freq)), vjust = 1) +\n  scale_fill_gradient(low = \"#F3F781\", high = \"#58FA82\") +\n  theme_economist() + theme(legend.position=\"none\", strip.background = element_blank(), strip.text.x = element_blank(), \n     plot.title=element_text(hjust=0.5, color=\"white\"), plot.subtitle=element_text(color=\"white\"), plot.background=element_rect(fill=\"#0D7680\"),\n                                                        axis.text.x=element_text(colour=\"white\"), axis.text.y=element_text(colour=\"white\"),\n                                                        axis.title=element_text(colour=\"white\"), \n     legend.background = element_rect(fill=\"#FFF9F5\",\n                                  size=0.5, linetype=\"solid\", \n                                  colour =\"black\")) + \nlabs(title=\"Confusion Matrix\", y=\"Attrition Status\", x=\"Predictions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"library(partykit)\n\nrparty.tree <- as.party(rpart.tree)\nrparty.tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pruning reduces the size of decision trees by removing parts of the tree that do not provide power to classify instances\n\nprune.rpart.tree <- prune(rpart.tree, cp=0.02) # pruning the tree\nplot(prune.rpart.tree, uniform=TRUE, branch=0.6)\ntext(prune.rpart.tree, all=TRUE, use.n=TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"library(rpart.plot)\nlibrary(RColorBrewer)\n\noptions(repr.plot.width=12, repr.plot.height=12) \n\nfancyRpartPlot(rpart.tree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}